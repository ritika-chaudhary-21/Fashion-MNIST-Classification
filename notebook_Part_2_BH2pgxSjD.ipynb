{"cells": [{"metadata": {}, "cell_type": "code", "source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='13450e8e-359e-46da-8b39-48ccc3f6c716', project_access_token='p-2+kYmmZTP1AJdDMFW5Qn0O2g==;xZG7uVwBXrKQ7p/R8OOkig==:aYf3JVf8yIvO5Q4Zm+SYe6xs7GkqZVX2+ln5JiPWxOz1BJ57a1LRIfKVL4yXmbcdPd8FEhh2TCKaUy4jqjUhR7OBGT8hWPfjxQ==')\npc = project.project_context\n\nfrom ibm_watson_studio_lib import access_project_or_space\nwslib = access_project_or_space({'token':'p-2+kYmmZTP1AJdDMFW5Qn0O2g==;xZG7uVwBXrKQ7p/R8OOkig==:aYf3JVf8yIvO5Q4Zm+SYe6xs7GkqZVX2+ln5JiPWxOz1BJ57a1LRIfKVL4yXmbcdPd8FEhh2TCKaUy4jqjUhR7OBGT8hWPfjxQ=='})\n\n", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='13450e8e-359e-46da-8b39-48ccc3f6c716', project_access_token='p-2+yQf1t4wzmMUQqXgf2z2yyw==;/USRXt9mqUZRKQUGzMvyEw==:Z3AWeGiYLadrq7dDyZQ09yl5G/0avK+6R5+qQNNwKv7jqLa7F7vavPSMd8J8nZwwfmWxv//9HPAgeeuIzp7Eq7i502kDdDRLMQ==')\npc = project.project_context\n\nfrom ibm_watson_studio_lib import access_project_or_space\nwslib = access_project_or_space({'token':'p-2+yQf1t4wzmMUQqXgf2z2yyw==;/USRXt9mqUZRKQUGzMvyEw==:Z3AWeGiYLadrq7dDyZQ09yl5G/0avK+6R5+qQNNwKv7jqLa7F7vavPSMd8J8nZwwfmWxv//9HPAgeeuIzp7Eq7i502kDdDRLMQ=='})", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Machine Learning and Model Comparisons on Fashion MNIST Dataset\n\nIn the first notebook `Part 1 - Data Exploration` we've explored the [Fashion-MNIST dataset from the Data Asset Exchange](https://developer.ibm.com/exchanges/data/all/fashion-mnist/). In this\nnotebook we will train three machine learning classifiers that could be used to identify fashion and clothing items and compare their performance. Throughout this notebook we will utilize the [scikit-learn](https://scikit-learn.org/) Machine Learning library. \n\n### Table of Contents:\n* [0. Prerequisites](#cell0)\n* [1. Prepare the Training Data](#cell1)\n* [2. Train a Decision Tree Classifier](#cell2)\n* [3. Train a Linear Classifier](#cell3)\n* [4. Train a Logistic Regression Classifier](#cell4)\n* [5. Compare Model Performance](#cell5)\n* [Authors](#authors)\n\n\n<a id=\"cell0\"></a>\n### 0. Prerequisites\n\nBefore you run this notebook complete the following steps:\n- Insert a project token\n- Install and import required packages\n\n#### Insert a project token\n\nWhen you import this project from the Watson Studio Gallery, a token should be automatically generated and inserted at the top of this notebook as a code cell such as the one below:\n\n```python\n# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='YOUR_PROJECT_ID', project_access_token='YOUR_PROJECT_TOKEN')\npc = project.project_context\n```\n\nIf you do not see the cell above, follow these steps to enable the notebook to access the dataset from the project's resources:\n\n* Click on `More -> Insert project token` in the top-right menu section\n\n![ws-project.mov](https://media.giphy.com/media/jSVxX2spqwWF9unYrs/giphy.gif)\n\n* This should insert a cell at the top of this notebook similar to the example given above.\n\n  > If an error is displayed indicating that no project token is defined, follow [these instructions](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/token.html?audience=wdp&context=data).\n\n* Run the newly inserted cell before proceeding with the notebook execution below\n\n#### Import required packages"}, {"metadata": {}, "cell_type": "code", "source": "# Define required imports\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cell1\"></a>\n\n### 1. Prepare the Training Data\n\nWe start by reading in the training dataset from `fashion-mnist_train.csv`."}, {"metadata": {}, "cell_type": "code", "source": "# Training dataset file name\nDATA_PATH = 'fashion-mnist_train.csv'\n\n# Create method to find filepath based on filename\ndef get_file_handle(fname):\n    # Project data path for the raw data file\n    data_path = project.get_file(fname)\n    data_path.seek(0)\n    return data_path\n\n# Usepandas to read the data \ndata_path = get_file_handle(DATA_PATH)\ndata = pd.read_csv(data_path).values\n\n# Preview data (label, followed by pixel data)\ndata", "execution_count": 4, "outputs": [{"output_type": "execute_result", "execution_count": 4, "data": {"text/plain": "array([[2, 0, 0, ..., 0, 0, 0],\n       [9, 0, 0, ..., 0, 0, 0],\n       [6, 0, 0, ..., 0, 0, 0],\n       ...,\n       [8, 0, 0, ..., 0, 0, 0],\n       [8, 0, 0, ..., 0, 0, 0],\n       [7, 0, 0, ..., 0, 0, 0]])"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": " Save the pixel data and labels into two arrays. "}, {"metadata": {}, "cell_type": "code", "source": "# Save the pixel data as \"pixel\"\npixel = data[:, 1:]\n\n# Save the label data as \"label\"\nlabel = data[:, 0]", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We are going to train three Machine Learning algorithms using this data that could be used to identify fashion and clothing items.\n\n#### Define helper functions\n\nDefine a helper function named `calculate_metrics`, which calculates the following metrics:\n- Accuracy, which we define here as the number of correct results returned by the classifier divided by total number of classifier examples.\n- [Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)\n- [F-score or F1-score](https://en.wikipedia.org/wiki/F1_score)\n\n\n`display_metrics` and `display_scores` are used throughout the notebook to display metrics."}, {"metadata": {}, "cell_type": "code", "source": "def calculate_metrics(label, label_predict):\n    \"\"\"\n    Calculate accuracy, precision, recall and f-score\n    \"\"\"\n    acc_score = accuracy_score(label, label_predict)\n    pre_score = precision_score(label, label_predict, average='weighted')\n    rec_score = recall_score(label, label_predict, average='weighted')\n    f_score = f1_score(label, label_predict, average='weighted')\n    return (acc_score, pre_score, rec_score, f_score)\n\ndef display_metrics(label, label_predict):\n    \"\"\"\n    Calculate and display accuracy, precision, recall and f-score\n    \"\"\"\n    scores = calculate_metrics(label, label_predict)\n    print(\"Model Accuracy : {}\".format(scores[0]))\n    print(\"Model Precision: {}\".format(scores[1]))\n    print(\"Model Recall   : {}\".format(scores[2]))\n    print(\"Model F-Score  : {}\".format(scores[3]))\n\n    \ndef display_scores(scores):\n    \"\"\"\n    Display scores (e.g. accuracy, precision, etc.) and calculate mean\n    and standard deviation\n    \"\"\"\n    print(\"Scores            : {}\".format(scores))\n    print(\"Mean              : {}\".format(scores.mean()))\n    print(\"Standard deviation: {}\".format(scores.std()))\n    ", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cell2\"></a>\n### 2.Train a  Decision Tree Classifier\n\nA [decision tree](https://en.wikipedia.org/wiki/Decision_tree) is a supervised machine learning technique that can be used to classify data. A decision tree consists of three components: internal nodes, edges/branches and leaf nodes.\n- Internal nodes test on attributes and produce a Yes/True or No/False answer. For example, a node might determine whether a picture contain sleeves.\n- Edges/Branches: Connection between each node or leaf to reflect the outcome of a test. For example, for the above node the answer `Yes` would be an edge to another node that might determine whether the sleeves are long. \n- Leaf nodes predict the outcome. For example, a picture is classified as `Pullover` if the previous test determined that the garment has long sleeves. \n\nWe will use a [scikit-learn implementation of the Decision Tree Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) and configure it to build a Decision Tree classifier from the pixel and label training data. As [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)) we use a combination that [performed well in these benchmarks](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#) and yields results quickly. We specify an arbitrary random number generator seed of 42 to allow for reproducible results."}, {"metadata": {}, "cell_type": "code", "source": "# Build an sklearn.tree.DecisionTreeClassifier from the training dataset\ndecision_tree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=10, random_state=42)\n\n# Train the classifier\ndecision_tree.fit(pixel, label)", "execution_count": 7, "outputs": [{"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "DecisionTreeClassifier(max_depth=10, random_state=42)", "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\u25b8\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\u25be\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, random_state=42)</pre></div></div></div></div></div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Test the decision tree classifier using the pixel training data. For illustrative purposes we also display the first 20 predictions and expected results to allow for a quick visual comparison."}, {"metadata": {}, "cell_type": "code", "source": "# Test classifier using the pixel data\nlabel_predict = decision_tree.predict(pixel)\n\n# Review the first 20 labels and predicted labels\nprint('Correct labels  : {}'.format(label[:20]))\nprint('Predicted labels: {}'.format(label_predict[:20]))", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "Correct labels  : [2 9 6 0 3 4 4 5 4 8 0 8 9 0 2 2 9 3 3 3]\nPredicted labels: [2 9 4 0 3 4 4 5 4 8 0 8 9 6 2 2 9 3 0 3]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Looking at this small sample, we can already see that not all predictions were correct. Let's calculate and display model accuracy, precision, recall and F-score for the trained classifier."}, {"metadata": {}, "cell_type": "code", "source": "# display model performance stats\ndisplay_metrics(label, label_predict)", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "Model Accuracy : 0.8479666666666666\nModel Precision: 0.8507829440982037\nModel Recall   : 0.8479666666666666\nModel F-Score  : 0.848208267661459\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "The trained model has good accuracy, precision, recall and F-score."}, {"metadata": {}, "cell_type": "markdown", "source": "#### Validate model performance using 3-fold Cross Validation\n\n[Cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)), sometimes called rotation estimation or out-of-sample testing, is one of the various model validation techniques for assessing how well the results of a statistical analysis generalize to an independent data set. It is a statistical method used to estimate the performance of machine learning models. The goal of cross-validation is to test the model's ability to predict on new data that was not used in estimating it, in order to flag problems like overfitting or selection bias and to give an insight on how the model will generalize to an independent dataset.\n\nThe general [procedure](https://machinelearningmastery.com/k-fold-cross-validation/) for k-fold cross validation is as follows:\n\n   1. Shuffle the dataset randomly.\n   1. Split the dataset into k groups\n   1. For each unique group:\n       1. Take the group as a hold out or test data set\n       1. Take the remaining groups as a training data set\n       1. Fit a model on the training set and evaluate it on the test set\n       1. Retain the evaluation score and discard the model\n   1. Summarize the skill of the model using the sample of model evaluation scores\n    \n        Importantly, each observation in the data sample is assigned to an individual group and stays in that group for the duration of the procedure. This means that each sample is given the opportunity to be used in the hold out set 1 time and used to train the model k-1 times.\n\n    This approach involves randomly dividing the set of observations into k groups, or folds, of approximately equal size. The first fold is treated as a validation set, and the method is fit on the remaining k \u2212 1 folds.\n\nIn this notebook we perform 3-fold cross validation which means here k=3. \n\n"}, {"metadata": {}, "cell_type": "code", "source": "# Scaled Features not required for Decision Tree\ndecision_tree_scores = cross_val_score(decision_tree, pixel, label, cv=3, scoring=\"accuracy\") \ndisplay_scores(decision_tree_scores)\n\nlabel_predcv = cross_val_predict(decision_tree, pixel, label, cv=3)\ndecision_tree_cv = calculate_metrics(label,label_predcv)", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "Scores            : [0.80325 0.80905 0.8016 ]\nMean              : 0.8046333333333333\nStandard deviation: 0.0031948743672048177\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "The prediction performance of the model is fairly ok. The accuracy, precision, recall and F-score are around 80%. Let's try a different approach and see if we can achieve better prediction performances.\n\n<a id=\"cell3\"></a>\n### 3. Train a Linear Classifier\n\nIn the field of machine learning, the goal of statistical classification is to use an object's characteristics to identify which class (or group) it belongs to. A [Linear Classifier](https://en.wikipedia.org/wiki/Linear_classifier) achieves this by making a classification decision based on the value of a linear combination of the characteristics. An object's characteristics are also known as feature values and are typically presented to the machine in a vector called a feature vector.\n\nIn this notebook, we use the [scikit-learn implementation of a Linear SGD Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html). SGD refers to Stochastic Gradient Descent, which is an iterative algorithm to find the target weights of the linear classifier. The feature vector in this case is a vector of pixel values from the image. \n\nA few points to keep in mind when we use this classifier:\n- It requires a number of hyperparameters such as the regularization parameter and the number of iterations.\n- It is sensitive to feature scaling. \n\nWe need to build up feature scaling carefully and choose hyperparameters wisely.\n\nEach image in the dataset has 784 features (28x28 pixels vectorized into 784x1 vector) and the value of each pixel ranges from 0 to 255. We use sklearn's [`sklearn.preprocessing.StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html?highlight=standardscaler#sklearn.preprocessing.StandardScaler) class to perform [feature scaling](https://en.wikipedia.org/wiki/Feature_scaling) on the dataset so that the values are in weighted form and in a smaller range. The scaling formula is `x_scaled = (x - x_mean) / x_standarddeviation`, which is also known as the z-score in statistical analysis. It means how many standard deviation is each point away from the mean value. "}, {"metadata": {}, "cell_type": "code", "source": "# Create an sklearn.preprocessing.StandardScaler instance\nscaler = StandardScaler()\n\n# Map pixels with the Scaler\npixel_scaled = scaler.fit_transform(pixel.astype(np.float64))", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Build and train a Linear SGD Classifier from the training dataset using a combination of hyperparameters that [performed well in these benchmarks](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#) and yields results quickly. We specify an arbitrary random number generator seed of 42 to allow for reproducible results."}, {"metadata": {}, "cell_type": "code", "source": "# Create an sklearn.linear_model.SGDClassifier\nsgd = SGDClassifier(loss='hinge', random_state=42, penalty='l2')\n\n# train the classifier using the labels and the feature-scaled pixel values \nsgd.fit(pixel_scaled, label)", "execution_count": 12, "outputs": [{"output_type": "execute_result", "execution_count": 12, "data": {"text/plain": "SGDClassifier(random_state=42)", "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\u25b8\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\u25be\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=42)</pre></div></div></div></div></div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Test the Linear SGD Classifier using the scaled pixel training data."}, {"metadata": {}, "cell_type": "code", "source": "# Test classifier using the pixel data\nlabel_predict = sgd.predict(pixel_scaled)\n\n# display model performance stats\ndisplay_metrics(label, label_predict)", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "Model Accuracy : 0.8433833333333334\nModel Precision: 0.8450830852313301\nModel Recall   : 0.8433833333333334\nModel F-Score  : 0.8436635148245399\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Validate model performance using 3-fold Cross Validation"}, {"metadata": {}, "cell_type": "code", "source": "sgd_scores = cross_val_score(sgd, pixel_scaled, label, cv=3, scoring=\"accuracy\") \ndisplay_scores(sgd_scores)\n\nlabel_predcv = cross_val_predict(sgd, pixel_scaled, label, cv=3)\nlinear_classifier_cv = calculate_metrics(label,label_predcv)", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "Scores            : [0.8372  0.8284  0.83025]\nMean              : 0.83195\nStandard deviation: 0.0037883593634536247\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "It appears that the trained Linear SGD Classifier is performing better than the Decision Tree classifier. Let's try one more classifier."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cell4\"></a>\n### 4. Train a Logistic Regression Classifier\n\nIn statistics, the [logistic model](https://en.wikipedia.org/wiki/Logistic_regression) (or logit model) is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick. This can be extended to model several classes of events such as determining whether an image contains a cat, dog, lion, etc. Each object being detected in the image would be assigned a probability between 0 and 1. Logistic regression is a supervised classification algorithm.\n\nIn this notebook we use the [scikit-learn implementation of a Logistic Regression Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#) and apply a hyperparameter combination that [performed well in these benchmarks](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#) and yields results quickly. We specify an arbitrary random number generator seed of 42 to allow for reproducible results."}, {"metadata": {}, "cell_type": "code", "source": "# Create an sklearn.linear_model.LogisticRegression classifier\nlog = LogisticRegression(multi_class=\"ovr\", penalty='l2', solver=\"lbfgs\", C=10, random_state=42)\n\n# train the classifier using the labels and the feature-scaled pixel values \nlog.fit(pixel_scaled, label)", "execution_count": 15, "outputs": [{"output_type": "execute_result", "execution_count": 15, "data": {"text/plain": "LogisticRegression(C=10, multi_class='ovr', random_state=42)", "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\u25b8\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\u25be\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, multi_class=&#x27;ovr&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, multi_class=&#x27;ovr&#x27;, random_state=42)</pre></div></div></div></div></div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Test the Logistic Regression Classifier using the feature-scaled pixel training data."}, {"metadata": {}, "cell_type": "code", "source": "# predict dataset pixel_scaled using trained model\nlabel_predict = log.predict(pixel_scaled)\n\n# display model performance stats\ndisplay_metrics(label, label_predict)", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "Model Accuracy : 0.8741833333333333\nModel Precision: 0.8727096964466472\nModel Recall   : 0.8741833333333333\nModel F-Score  : 0.8729069607719379\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Validate model performance using 3-fold Cross Validation"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "log_scores = cross_val_score(log, pixel_scaled, label, cv=3, scoring=\"accuracy\") \ndisplay_scores(log_scores)\n\nlabel_predcv = cross_val_predict(log, pixel_scaled, label, cv=3)\nlog_regression_cv = calculate_metrics(label,label_predcv)", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "Scores            : [0.8466  0.8456  0.84365]\nMean              : 0.8452833333333333\nStandard deviation: 0.0012249716550008674\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "The prediction power of the Logistic Regression Classifier is slightly better than that of the SGD Classifier, comparing their 3-fold cross validation scores. \n\n<a id=\"cell5\"></a>\n\n### 5. Compare Model Performance\n\nLet's compare the three model's cross validation performance side by side!"}, {"metadata": {}, "cell_type": "code", "source": "model_comparison_df = pd.DataFrame([decision_tree_cv, linear_classifier_cv, log_regression_cv], \n                                   columns =['Accuracy', 'Precision', 'Recall', 'F-Score'], \n                                   index=['decision_tree_cv', 'linear_classifier_cv', 'log_regression_cv'])\nmodel_comparison_df", "execution_count": 18, "outputs": [{"output_type": "execute_result", "execution_count": 18, "data": {"text/plain": "                      Accuracy  Precision    Recall   F-Score\ndecision_tree_cv      0.804633   0.805922  0.804633  0.803913\nlinear_classifier_cv  0.831950   0.832003  0.831950  0.831457\nlog_regression_cv     0.845283   0.843178  0.845283  0.843750", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F-Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>decision_tree_cv</th>\n      <td>0.804633</td>\n      <td>0.805922</td>\n      <td>0.804633</td>\n      <td>0.803913</td>\n    </tr>\n    <tr>\n      <th>linear_classifier_cv</th>\n      <td>0.831950</td>\n      <td>0.832003</td>\n      <td>0.831950</td>\n      <td>0.831457</td>\n    </tr>\n    <tr>\n      <th>log_regression_cv</th>\n      <td>0.845283</td>\n      <td>0.843178</td>\n      <td>0.845283</td>\n      <td>0.843750</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "In our example a comparison of accuracy, precision, recall, and F-score indicates that the trained Linear Regression classfier would yield the best prediction results.\n\n\n#### Next steps\n\n- Close this notebook.\n- Open the `Part 3 - DL and Model Evaluations` notebook.\n\n\n<a id=\"authors\"></a> \n### Authors\n\nThis notebook was created by the [Center for Open-Source Data & AI Technologies](http://codait.org).\n<br><br>\n\nCopyright \u00a9 2020-2022 IBM. This notebook and its source code are released under the terms of the MIT License.\n<br><br>\n<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n</div>"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.14", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}